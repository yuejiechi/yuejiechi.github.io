
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Yuejie Chi</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tbody><tr valign="top">
<td id="layout-menu">
<div class="menu-category"><img class="menu" src="CMU_logo.png" width="100px" align="center"></div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publications.html">Papers</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-item"><a href="service.html">Service</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Yuejie Chi</h1>
<div id="subtitle"><a href="http://www.cmu.edu">Carnegie Mellon University</a></div>
</div>

<table class="imgtable"><tbody><tr><td>
<img src="ychi_homepage.jpg" alt="" width="200px" style="padding-left:10px", "padding-right:10px">&nbsp&nbsp&nbsp;
<td align="left"><p><br>
<b>Yuejie Chi</b><br>
Sense of Wonder Group Endowed Professor<br>
Department of Electrical and Computer Engineering<br>
Carnegie Mellon University<br>
<a href="shortbio.html"><b>Short Bio</b></a> &nbsp/&nbsp <a href="cv_ychi_web.pdf"><b>CV</b></a> &nbsp/&nbsp  <a href="https://scholar.google.com/citations?user=h1NXfKYAAAAJ&hl=en"><b>Google Scholar</b></a><br></p>
</td></tr></tbody></table>
<p><br> </p>  
<p>I am the Sense of Wonder Group Endowed Professor of <a href="http://ece.cmu.edu">Electrical and Computer Engineering</a> in AI Systems</a> at <a href="http://www.cmu.edu">Carnegie Mellon University</a>. I am also an affiliated faculty member with the <a href="http://www.ml.cmu.edu/">Machine Learning Department</a> and <a href="https://www.cylab.cmu.edu/">CyLab</a>. My department homepage is <a href="https://www.ece.cmu.edu/directory/bios/chi-yuejie.html">here</a>.

<p>My research interests lie in the theoretical and algorithmic foundations of data science, machine learning, signal processing and inverse problems, with applications in sensing, imaging, decision making, and societal systems, broadly defined. The problems my group studies are often interdisciplinary in nature, lying at the intersection of statistics, learning, optimization, and sensing. Specific lines of research topics can be found <a href="research.html">here</a>.
 
<p>I have been lucky to receive a couple of awards for my work, including Presidential Early Career Award for Scientists and Engineers (PECASE) from the White House, the highest honor bestowed by the United States Government to outstanding early-career scientists and engineers who show exceptional promise for leadership in science and technology. In 2019, I received the <i>inaugural</i> IEEE Signal Processing Society Early Career Technical Achievement Award for contributions to high-dimensional structured signal processing. In addition, I received IEEE Signal Processing Society Young Author Best Paper Award, and young investigator awards from several agencies including NSF, ONR and AFOSR. 

<p>I am an IEEE Fellow (Class of 2023) for contributions to statistical signal processing with low-dimensional structures. [<a href="https://www.ece.cmu.edu/news-and-events/story/2022/12/chi-ieee-fellow.html">ECE News</a>] [<a href="https://www.cs.cmu.edu/news/2022/2023-ieee-fellows">SCS News</a>] 

<p>I also had the privilege to deliver plenary, keynote and tutorial talks at several conferences and workshops, with more materials shared <a href="talks.html">here</a>. I was named the <a href="https://www.itsoc.org/honors/goldsmith-lecture">Goldsmith Lecturer</a> by IEEE Information Theory Society in 2021, and a <a href="https://signalprocessingsociety.org/professional-development/distinguished-lecturers">Distinguished Lecturer</a> by IEEE Signal Processing Society for 2022-2023.

<p>Previously I was with the Dept. of <a href="http://ece.osu.edu/">Electrical and Computer Engineering</a> and the Dept. of <a href="http://medicine.osu.edu/bmi/Pages/index.aspx">Biomedical Informatics</a> at <a href="http://www.osu.edu/">The Ohio State University</a> until 2017. I completed my Ph.D. in Electrical Engineering from <a href="http://www.ee.princeton.edu/">Princeton University</a> in 2012, where I was fortunate to be advised by <a href="http://ece.duke.edu/faculty/robert-calderbank">Prof. Robert Calderbank</a>. I received a M.A. in Electrical Engineering from Princeton University in 2009, and a B.Eng. in Electronic Engineering from <a href="http://www.tsinghua.edu.cn/publish/eeen/">Tsinghua University</a> in 2007. 

<p>I have an Erdos number of 3.</p>
 
<p><b>Notes to prospective students outside CMU:</b> There is on expectation 1 slot in my group every year. Unfortunately, I am not able to respond to most (nearly all!) inquiries about suitability in my group due to the volume of emails I receive. Instead, please apply directly to the ECE department and list me as a faculty of interest. Occasionally, I take summer interns and visitors with strong mathematical backgrounds. </b> 

<p><b>Notes to students at CMU:</b> Please contact me directly if you're interested in <a href="research.html">research</a> projects in my group.  </b> 



<h2>Upcoming Events</h2>
<ul>   
<li><p>We are organizing a new <a href="https://cpal.cc/">Conference on Parsimony and Learning (CPAL)</a> at Hong Kong, January 2024. Please consider submitting! 
<li><p>Call for paper: IEEE Journal of Selected Topics in Signal Processing Special Issue on <a href="https://signalprocessingsociety.org/publications-resources/special-issue-deadlines/ieee-jstsp-special-issue-seeking-low-dimensionality-deep-neural-networks-slowdnn">Seeking Low-dimensionality in Deep Neural Networks</a>. Please consider submitting! 
<li><p>Aug. 2023: <b>Short course</b> on "Statistical and Algorithmic Foundations of Reinforcement Learning" at JSM 2023, joint with Y. Wei and Y. Chen from UPenn.
<li><p>Oct. 2023: <b>Plenary speaker</b> at the inaugural <a href="https://sites.google.com/view/siam-nynjpa/annual-meeting">SIAM-NNP Annual Meeting</a>.
<li><p>Nov. 2023: <b>Speaker</b> at <a href="https://deepmath-conference.com/">Conference on the Mathematical Theory of Deep Neural Network (DeepMath)</a>.
</ul>

<h2>Recent Papers</h2>
<ul>
<li><p>Understanding the sample complexity of <b>reinforcement learning</b>:
<ul> 
<li><p><a href="papers/DRO-Simulator.pdf">The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model</a> <a href="https://arxiv.org/abs/2305.16589">[Arxiv]</a>
<li><p><a href="papers/Federated_Qlearning.pdf">The Blessing of Heterogeneity in Federated Q-Learning: Linear Speedup and Beyond</a> <a href="https://arxiv.org/abs/2305.10697">[Arxiv]</a> 
<li><p><a href="papers/Policy_finetuning.pdf">Reward-agnostic Fine-tuning: Provable Statistical Benefits of Hybrid Reinforcement Learning</a> <a href="https://arxiv.org/abs/2305.10282">[Arxiv]</a>
<li> <p><a href="papers/ModelBased_OfflineRL.pdf">Settling the Sample Complexity of Model-Based Offline Reinforcement Learning</a> <a href="https://arxiv.org/pdf/2204.05275.pdf">[Arxiv]</a>  
<li><p><a href="papers/DRO_OfflineRL.pdf">Distributionally Robust Model-Based Offline Reinforcement Learning with Near-Optimal Sample Complexity</a> <a href="https://arxiv.org/abs/2208.05767">[Arxiv]</a>  
</ul>
 <li><p>Statistical and computational complexities of <b>multi-agent reinforcement learning</b>: </p>
<ul>
<li><p><a href="papers/MarkovGame_PolicyOpt.pdf">Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games</a> <a href="https://arxiv.org/abs/2210.01050">[Arxiv]</a>
<li><p><a href="papers/EntropyGame.pdf">Fast Policy Extragradient Methods for Competitive Games with Entropy Regularization</a> <a href="https://arxiv.org/pdf/2105.15186.pdf">[Arxiv]</a>
<li> <p><a href="papers/Markov_games_simulator.pdf">Minimax-Optimal Multi-Agent RL in Markov Games With a Generative Model</a> <a href="https://arxiv.org/abs/2208.10458">[Arxiv]</a> 
</ul>
 <li><p>Resource-efficient and private algorithms for <b>federated learning</b>: </p>
 <ul>
 <li><p><a href="papers/PORTER.pdf">Convergence and Privacy of Decentralized Nonconvex Optimization with Gradient Clipping and Communication Compression</a> <a href="https://arxiv.org/abs/2305.09896">[Arxiv]</a>
 <li><p><a href="papers/SoteriaFL.pdf">SoteriaFL: A Unified Framework for Private Federated Learning with Communication Compression</a>
<li> <p><a href="papers/BEER.pdf">BEER: Fast O(1/T) Rate for Decentralized Nonconvex
Optimization with Communication Compression</a> 
</ul>
<li><p>Scaled gradient descent for <b>ill-conditioned low-rank matrix and tensor estimation</b>: </p>
<ul>
<li><p><a href="papers/ScaledGD_Overparam.pdf">The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing</a> 
<li><p><a href="papers/Tensor_ScaledGD.pdf">Scaling and Scalability: Provable Nonconvex Low-Rank Tensor Estimation from Incomplete Measurements</a>
<li><p><a href="papers/Tensor_RPCA.pdf">Fast and Provable Tensor Robust Principal Component Analysis via Scaled Gradient Descent</a>
<li><p><a href="papers/ScaledGD.pdf">Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled Gradient Descent</a>
<li><p><a href="papers/ScaledSM.pdf">Low-Rank Matrix Recovery with Scaled Subgradient Methods: Fast and Robust Convergence Without the Condition Number</a>
</ul>
</ul>
 

<h2>Contact</h2>
<ul>
<li><p>Office: Porter Hall B25
<li><p>Mailing address: 5000 Forbes Ave., Pittsburgh, PA 15213</p>
<li><p>Email: first+last at cmu dot edu = first+c at andrew dot cmu dot edu</p>
</li>
</ul>

<p><br></p>
<div id="footer">
<div id="footer-text">
Page generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</tbody></table>


</body></html>