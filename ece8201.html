
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yuejie Chi</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category"><img class="menu" src="yale_logo.png" width="100px" align="center"></div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publications.html">Papers</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="teaching.html" class="current">Teaching</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-item"><a href="service.html">Service</a></div>
<div class="menu-item"><a href="news.html">News</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Yuejie Chi</h1>
</div>

<h2>ECE 8201: Advanced Topics in Signal Processing (Offered at OSU)</h2>

This course will discuss advances in sampling and analysis of high-dimensional data under the umbrella
of subspace methods, including low-dimensional data models such as sparse and low-rank models, convex
and non-convex approaches for solving linear inverse problems, dimensionality reduction, clustering, and
streaming data processing, with applications in signal processing, machine learning, imaging and network
inference. The goal of the course is to develop expertise at the intersection of optimization, signal processing,
statistics and computer science to address emerging challenges of data science.

<br>
<h3><a href="ece8201_notes/ece8201_syllabus_fall2015.pdf">Course Syllabus</a></h3>

<h3>Lecture Notes</h3>
<ul>
<li> <a href="ece8201_notes/ece8201_lecture1.pdf">Lecture 1: Introduction</a>
<li> <a href="ece8201_notes/ece8201_lecture2.pdf">Lecture 2: Sparse Signal Recovery via Basis Pursuit with RIP</a>
<li> <a href="ece8201_notes/ece8201_lecture3.pdf">Lecture 3: Sparse Signal Recovery via Basis Pursuit without RIP</a>
<li> <a href="ece8201_notes/ece8201_lecture4.pdf">Lecture 4: Sparse Signal Recovery via Greedy Algorithms</a>
<li> <a href="ece8201_notes/ece8201_lecture5.pdf">Lecture 5: FISTA</a>
<li> Lecture 6: Concentration inequalities
<li> <a href="ece8201_notes/ece8201_lecture7.pdf">Lecture 7: Matrix Completion</a>
<li> <a href="ece8201_notes/ece8201_lecture8.pdf">Lecture 8: Robust PCA</a>
<li> <a href="ece8201_notes/ece8201_lecture9.pdf">Lecture 9: Atomic Norms</a>
</ul>

<h3>Reading List (Compiled by Y. Chi, last update Sep. 1, 2015):</h3>


<br>
<li> Reference textbook:</li>
<ul>
<li> S. Foucart and H. Rauhut. A Mathematical Introduction to Compressive Sensing.
</li></ul>

<li> Sparse recovery with \ell-1 optimization:</li>
<ul>
<li> D. Donoho and M. Elad. Optimally Sparse Representation in General
(non-Orthogonal) Dictionaries via \ell-1 Minimization. <a href="http://statweb.stanford.edu/~donoho/Reports/2002/OptSparse.pdf">PDF</a>
<li> E. J. Candes. The restricted isometry property and its implications for compressed sensing. <a href="http://statweb.stanford.edu/~candes/papers/RIP.pdf">PDF</a>
<li> E. J. Candes and Y. Plan. A Probabilistic and RIPless Theory of Compressed Sensing. <a href="http://arxiv.org/pdf/1011.3854v3.pdf">PDF</a>

<li> D. Donoho. Compressed Sensing. <a href="http://statweb.stanford.edu/~donoho/Reports/2004/CompressedSensing091604.pdf">PDF</a>
<li> R. Baraniuk, M. Davenport, R. DeVore and M. Wakin. A Simple Proof of the Restricted Isometry Property for Random Matrices. <a href="http://dsp.rice.edu/sites/dsp.rice.edu/files/publications/journal-article/2008/bddw-ca-2008.pdf">PDF</a>

<li> E. J. Candes and T. Tao. The Dantzig Selector: Statistical Estimation When p Is Much Larger than n. <a href="http://statweb.stanford.edu/~candes/papers/DantzigSelector.pdf">PDF</a>

<li> E. J. Candes and Y. Plan. Near-ideal model selection by \ell-1 minimization. <a href="http://statweb.stanford.edu/~candes/papers/LassoPredict.pdf">PDF</a></li>
</ul> 

<li> Sparse recovery with greedy pursuit:</li>
<ul>
<li> J. A. Tropp. Greed is Good: Algorithmic Results for Sparse Approximation. <a href="http://authors.library.caltech.edu/9035/1/TROieeetit04a.pdf">PDF</a>
</li><li> J. A. Tropp and A. C. Gilbert. Signal Recovery from Random Measurements via Orthogonal Matching Pursuit. <a href="http://users.cms.caltech.edu/~jtropp/papers/TG07-Signal-Recovery.pdf">PDF</a>
</li><li> D. Needell and J. A. Tropp. CoSaMP: Iterative signal recovery from incomplete and inaccurate samples. <a href="http://www1.cmc.edu/pages/faculty/DNeedell/papers/cosamp.pdf">PDF</a>

</li><li> M. A. Davenport and M. B. Wakin. Analysis of Orthogonal Matching Pursuit
Using the Restricted Isometry Property. <a href="http://dsp.rice.edu/sites/dsp.rice.edu/files/publications/journal-article/2010/dw-tit-2010.pdf">PDF</a></ul>
</li></ul>

<li> Advanced topics on sparse recovery:</li>
<ul>
<li> D. L. Donoho, A. Maleki, and A. Montanari. Message Passing Algorithms for Compressed Sensing. <a href="http://arxiv.org/abs/0907.3574">PDF</a>
</li><li> R. Calderbank, S. Howard and S. Jafarpour. Construction of a Large Class of Deterministic Sensing Matrices that Satisfy a Statistical Isometry Property. <a href="http://arxiv.org/pdf/0910.1943.pdf">PDF</a>
</li><li> Y. Plan and R. Vershynin. One-bit compressed sensing by linear programming. <a href="http://arxiv.org/pdf/1109.4299.pdf">PDF</a></ul>
</li></ul>



<li> Low-rank matrix completion:</li>
<ul>
<li> B. Recht. A Simpler Approach to Matrix Completion. <a href="http://arxiv.org/pdf/0910.0651.pdf">PDF</a>
<li> B. Recht, M. Fazel, and P. A. Parrilo. Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization. <a href="http://arxiv.org/pdf/0706.4138.pdf">PDF</a>
<li> R. Mazumder, T. Hastie, and R. Tibshirani. Spectral regularization algorithms for learning large incomplete matrices. <a href="http://web.stanford.edu/~hastie/Papers/mazumder10a.pdf">PDF</a>
<li> S. Negahban and M. J. Wainwright. Restricted strong convexity and weighted matrix completion: Optimal bounds with noise. <a href="http://arxiv.org/abs/1009.2118">PDF</a>
</li></ul>

<li> High-dimensional structural inference:</li>
<ul>
<li> E. D. Kolaczyk and R. D. Nowak. Multiscale likelihood analysis and complexity penalized estimation. <a href="http://projecteuclid.org/euclid.aos/1083178936">PDF</a>
<li> S. N. Negahban, P. Ravikumar, M. J. Wainwright and B. Yu. A Unified Framework for High-Dimensional Analysis of M-Estimators with Decomposable Regularizers. <a href="http://www.stat.yale.edu/~snn7/papers/NegRavWaiYu12_Full.pdf">PDF</a>
<li> V. Chandrasekaran, B. Recht, P. A. Parrilo, and A. S. Willsky. The Convex Geometry of Linear Inverse Problems. <a href="http://arxiv.org/pdf/1012.0621.pdf">PDF</a>
</li></ul>

<li> Sparse spectrum analysis and time-frequency analysis:</li>
<ul>
<li> Y. Chi, L. L. Scharf, A. Pezeshki, and A. R. Calderbank. Sensitivity to basis mismatch in compressed sensing. <a href="http://www2.ece.ohio-state.edu/~chi/papers/CSmismatch_journal.pdf">PDF</a>
<li> E. J. Candes and C. Fernandez-Granda. Towards a mathematical theory of super-resolution. <a href="http://statweb.stanford.edu/~candes/papers/super-res.pdf">PDF</a>
</li></ul>

<li> Streaming models and online learning:</li>
<ul>
<li> S. Muthukrishnan. Data Streams: Algorithms and Applications. <a href="https://cs.uwaterloo.ca/~david/cs848/Muthu-Survey.pdf">PDF</a>
<li>P. Indyk. Sketching, streaming, and sub-linear space algorithms. <a href="http://people.csail.mit.edu/indyk/ita-web.pdf">PDF</a>

</li></ul>
 
 

<p><br /><br /></p>
<div id="footer">
<div id="footer-text">
Page generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>